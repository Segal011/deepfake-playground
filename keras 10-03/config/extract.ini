[global]
# OPTIONS THAT APPLY TO ALL EXTRACTION PLUGINS

# [Nvidia Only]. Enable the Tensorflow GPU `allow_growth` configuration option. This option prevents
# Tensorflow from allocating all of the GPU VRAM at launch but can lead to higher VRAM fragmentation
# and slower performance. Should only be enabled if you are having problems running extraction.
# 
# Choose from: True, False
# [Default: False]
allow_growth = False

[align.fan]
# FAN ALIGNER OPTIONS.
# FAST ON GPU, SLOW ON CPU. BEST ALIGNER.

# The batch size to use. To a point, higher batch sizes equal better performance, but setting it too
# high can harm performance.
# 
#     - Nvidia users: If the batchsize is set higher than the your GPU can accomodate then this will
# 		automatically be lowered.
#     - AMD users: A batchsize of 8 requires about 4 GB vram.
# 
# Select an integer between 1 and 64
# [Default: 12]
batch-size = 12

[detect.cv2_dnn]
# CV2 DNN DETECTOR OPTIONS.
# A CPU ONLY EXTRACTOR, IS THE LEAST RELIABLE, BUT USES LEAST RESOURCES AND RUNS FAST ON CPU. USE THIS
# IF NOT USING A GPU AND TIME IS IMPORTANT

# The confidence level at which the detector has succesfully found a face.
# Higher levels will be more discriminating, lower levels will have more false positives.
# 
# Select an integer between 25 and 100
# [Default: 50]
confidence = 50

[detect.mtcnn]
# MTCNN DETECTOR OPTIONS.
# FAST ON GPU, SLOW ON CPU. USES FEWER RESOURCES THAN OTHER GPU DETECTORS BUT CAN OFTEN RETURN MORE
# FALSE POSITIVES.

# The minimum size of a face (in pixels) to be accepted as a positive match.
# Lower values use significantly more VRAM and will detect more false positives.
# 
# Select an integer between 20 and 1000
# [Default: 20]
minsize = 20

# The scale factor for the image pyramid.
# 
# Select a decimal number between 0.1 and 0.9
# [Default: 0.709]
scalefactor = 0.709

# The batch size to use. To a point, higher batch sizes equal better performance, but setting it too
# high can harm performance.
# 
#     - Nvidia users: If the batchsize is set higher than the your GPU can accomodate then this will
# 		automatically be lowered.
# 
# Select an integer between 1 and 64
# [Default: 8]
batch-size = 8

# [Nvidia Only] MTCNN detector still runs fairly quickly on CPU on some setups. Enable CPU mode here
# to use the CPU for this detector to save some VRAM at a speed cost.
# 
# Choose from: True, False
# [Default: True]
cpu = True

# First stage threshold for face detection. This stage obtains face candidates.
# 
# Select a decimal number between 0.1 and 0.9
# [Default: 0.6]
threshold_1 = 0.6

# Second stage threshold for face detection. This stage refines face candidates.
# 
# Select a decimal number between 0.1 and 0.9
# [Default: 0.7]
threshold_2 = 0.7

# Third stage threshold for face detection. This stage further refines face candidates.
# 
# Select a decimal number between 0.1 and 0.9
# [Default: 0.7]
threshold_3 = 0.7

[detect.s3fd]
# S3FD DETECTOR OPTIONS.
# FAST ON GPU, SLOW ON CPU. CAN DETECT MORE FACES AND FEWER FALSE POSITIVES THAN OTHER GPU DETECTORS,
# BUT IS A LOT MORE RESOURCE INTENSIVE.

# The confidence level at which the detector has succesfully found a face.
# Higher levels will be more discriminating, lower levels will have more false positives.
# 
# Select an integer between 25 and 100
# [Default: 70]
confidence = 70

# The batch size to use. To a point, higher batch sizes equal better performance, but setting it too
# high can harm performance.
# 
#     - Nvidia users: If the batchsize is set higher than the your GPU can accomodate then this will
# 		automatically be lowered.
#     - AMD users: A batchsize of 8 requires about 2 GB vram.
# 
# Select an integer between 1 and 64
# [Default: 4]
batch-size = 4

[mask.bisenet_fp]
# BISENET FACE PARSING OPTIONS.
# MASK PORTED FROM HTTPS://GITHUB.COM/ZLLRUNNING/FACE-PARSING.PYTORCH.

# The batch size to use. To a point, higher batch sizes equal better performance, but setting it too
# high can harm performance.
# 
#     - Nvidia users: If the batchsize is set higher than the your GPU can accomodate then this will
# 		automatically be lowered.
# 
# Select an integer between 1 and 64
# [Default: 8]
batch-size = 8

# [Nvidia Only] BiseNet mask still runs fairly quickly on CPU on some setups. Enable CPU mode here to
# use the CPU for this masker to save some VRAM at a speed cost.
# 
# Choose from: True, False
# [Default: False]
cpu = False

# The trained weights to use.
# 
#     - faceswap - Weights trained on wildly varied Faceswap extracted data to better handle varying
# 		conditions, obstructions, glasses and multiple targets within a single extracted image.
#     - original - The original weights trained on the CelebAMask-HQ dataset.
# 
# Choose from: ['faceswap', 'original']
# [Default: faceswap]
weights = faceswap

# Whether to include ears within the face mask.
# 
# Choose from: True, False
# [Default: False]
include_ears = False

# Whether to include hair within the face mask.
# 
# Choose from: True, False
# [Default: False]
include_hair = False

# Whether to include glasses within the face mask.
#     - For 'original' weights excluding glasses will mask out the lenses as well as the frames.
#     - For 'faceswap' weights, the model has been trained to mask out lenses if eyes cannot be seen
# 		(i.e. dark sunglasses) or just the frames if the eyes can be seen.
# 
# Choose from: True, False
# [Default: True]
include_glasses = True

[mask.custom]
# CUSTOM (DUMMY) MASK OPTIONS..
# THE CUSTOM MASK JUST FILLS A FACE PATCH WITH ALL 0'S (MASKED OUT) OR ALL 1'S (MASKED IN) FOR LATER
# MANUAL EDITING. IT DOES NOT USE THE GPU FOR CREATION.

# The batch size to use. To a point, higher batch sizes equal better performance, but setting it too
# high can harm performance.
# 
# Select an integer between 1 and 64
# [Default: 8]
batch-size = 8

# Whether to create a dummy mask with face or head centering.
# 
# Choose from: ['face', 'head']
# [Default: face]
centering = face

# Whether the mask should be filled (True) in which case the custom mask will be created with the
# whole area masked in (i.e. you would need to manually edit out the background) or unfilled (False)
# in which case you would need to manually edit in the face.
# 
# Choose from: True, False
# [Default: False]
fill = False

[mask.unet_dfl]
# UNET_DFL OPTIONS. MASK DESIGNED TO PROVIDE SMART SEGMENTATION OF MOSTLY FRONTAL FACES.
# THE MASK MODEL HAS BEEN TRAINED BY COMMUNITY MEMBERS. INSERT MORE COMMENTARY ON TESTING HERE.
# PROFILE FACES MAY RESULT IN SUB-PAR PERFORMANCE.

# The batch size to use. To a point, higher batch sizes equal better performance, but setting it too
# high can harm performance.
# 
#     - Nvidia users: If the batchsize is set higher than the your GPU can accomodate then this will
# 		automatically be lowered.
# 
# Select an integer between 1 and 64
# [Default: 8]
batch-size = 8

[mask.vgg_clear]
# VGG_CLEAR OPTIONS. MASK DESIGNED TO PROVIDE SMART SEGMENTATION OF MOSTLY FRONTAL FACES CLEAR OF
# OBSTRUCTIONS.
# PROFILE FACES AND OBSTRUCTIONS MAY RESULT IN SUB-PAR PERFORMANCE.

# The batch size to use. To a point, higher batch sizes equal better performance, but setting it too
# high can harm performance.
# 
#     - Nvidia users: If the batchsize is set higher than the your GPU can accomodate then this will
# 		automatically be lowered.
# 
# Select an integer between 1 and 64
# [Default: 6]
batch-size = 6

[mask.vgg_obstructed]
# VGG_OBSTRUCTED OPTIONS. MASK DESIGNED TO PROVIDE SMART SEGMENTATION OF MOSTLY FRONTAL FACES.
# THE MASK MODEL HAS BEEN SPECIFICALLY TRAINED TO RECOGNIZE SOME FACIAL OBSTRUCTIONS (HANDS AND
# EYEGLASSES). PROFILE FACES MAY RESULT IN SUB-PAR PERFORMANCE.

# The batch size to use. To a point, higher batch sizes equal better performance, but setting it too
# high can harm performance.
# 
#     - Nvidia users: If the batchsize is set higher than the your GPU can accomodate then this will
# 		automatically be lowered.
# 
# Select an integer between 1 and 64
# [Default: 2]
batch-size = 2

